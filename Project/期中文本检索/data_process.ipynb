{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本模块：数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入数据集\n",
    "import pandas as pd\n",
    "table = pd.read_csv(\"./data/all_news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# 去除标点\n",
    "def rid_of_specials(news):\n",
    "    return re.sub('[^A-za-z]+', ' ', news).lower()\n",
    "\n",
    "table[\"new_body\"] = table[\"body\"].astype(str).apply(rid_of_specials)\n",
    "\n",
    "sw_nltk = (stopwords.words('english'))\n",
    "stop_words = set(sw_nltk)\n",
    "\n",
    "# 去除停用词\n",
    "def remove_sw(x):\n",
    "    x = x.split(' ')\n",
    "    return  ' '.join(z for z in x if z not in stop_words)\n",
    "\n",
    "table['new_body'] = table[\"new_body\"].apply(remove_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分词、提取词根(词形还原)\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# 获取词性\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "# 提取词根\n",
    "def lemmatization(x):\n",
    "    tags = pos_tag(word_tokenize(x))\n",
    "    return ' '.join(lemmatizer.lemmatize(word=tag[0], pos=get_wordnet_pos(tag[1])) for tag in tags)\n",
    "\n",
    "table['new_body'] = table[\"new_body\"].apply(lemmatization)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quarterly', 'profits', 'at', 'US', 'media', 'giant', 'TimeWarner', 'jumped', '76%', 'to']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>topic</th>\n",
       "      <th>id</th>\n",
       "      <th>new_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at US media giant TimeWarner...</td>\n",
       "      <td>business</td>\n",
       "      <td>1</td>\n",
       "      <td>quarterly profit medium giant jump three month...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>The dollar has hit its highest level against t...</td>\n",
       "      <td>business</td>\n",
       "      <td>2</td>\n",
       "      <td>dollar hit high level euro almost three month ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>The owners of embattled Russian oil giant Yuko...</td>\n",
       "      <td>business</td>\n",
       "      <td>3</td>\n",
       "      <td>owner oil giant ask buyer former production un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>British Airways has blamed high fuel prices fo...</td>\n",
       "      <td>business</td>\n",
       "      <td>4</td>\n",
       "      <td>blame high fuel price drop profit report resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq</td>\n",
       "      <td>Shares in UK drinks and food firm Allied Domec...</td>\n",
       "      <td>business</td>\n",
       "      <td>5</td>\n",
       "      <td>share drink food firm risen speculation could ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>BT program to beat dialler scams</td>\n",
       "      <td>BT is introducing two initiatives to help beat...</td>\n",
       "      <td>tech</td>\n",
       "      <td>2221</td>\n",
       "      <td>introduce two initiative help beat cost net us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Spam e-mails tempt net shoppers</td>\n",
       "      <td>Computer users across the world continue to ig...</td>\n",
       "      <td>tech</td>\n",
       "      <td>2222</td>\n",
       "      <td>computer user across world continue ignore sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Be careful how you code</td>\n",
       "      <td>A new European directive could put software wr...</td>\n",
       "      <td>tech</td>\n",
       "      <td>2223</td>\n",
       "      <td>new directive could put software writer risk l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>US cyber security chief resigns</td>\n",
       "      <td>The man making sure US computer networks are s...</td>\n",
       "      <td>tech</td>\n",
       "      <td>2224</td>\n",
       "      <td>man make sure computer network safe secure res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Losing yourself in online gaming</td>\n",
       "      <td>Online role playing games are time-consuming, ...</td>\n",
       "      <td>tech</td>\n",
       "      <td>2225</td>\n",
       "      <td>online role play game time flight reality peop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  \\\n",
       "0     Ad sales boost Time Warner profit   \n",
       "1      Dollar gains on Greenspan speech   \n",
       "2     Yukos unit buyer faces loan claim   \n",
       "3     High fuel prices hit BA's profits   \n",
       "4     Pernod takeover talk lifts Domecq   \n",
       "...                                 ...   \n",
       "2220   BT program to beat dialler scams   \n",
       "2221    Spam e-mails tempt net shoppers   \n",
       "2222            Be careful how you code   \n",
       "2223    US cyber security chief resigns   \n",
       "2224   Losing yourself in online gaming   \n",
       "\n",
       "                                                   body     topic    id  \\\n",
       "0     Quarterly profits at US media giant TimeWarner...  business     1   \n",
       "1     The dollar has hit its highest level against t...  business     2   \n",
       "2     The owners of embattled Russian oil giant Yuko...  business     3   \n",
       "3     British Airways has blamed high fuel prices fo...  business     4   \n",
       "4     Shares in UK drinks and food firm Allied Domec...  business     5   \n",
       "...                                                 ...       ...   ...   \n",
       "2220  BT is introducing two initiatives to help beat...      tech  2221   \n",
       "2221  Computer users across the world continue to ig...      tech  2222   \n",
       "2222  A new European directive could put software wr...      tech  2223   \n",
       "2223  The man making sure US computer networks are s...      tech  2224   \n",
       "2224  Online role playing games are time-consuming, ...      tech  2225   \n",
       "\n",
       "                                               new_body  \n",
       "0     quarterly profit medium giant jump three month...  \n",
       "1     dollar hit high level euro almost three month ...  \n",
       "2     owner oil giant ask buyer former production un...  \n",
       "3     blame high fuel price drop profit report resul...  \n",
       "4     share drink food firm risen speculation could ...  \n",
       "...                                                 ...  \n",
       "2220  introduce two initiative help beat cost net us...  \n",
       "2221  computer user across world continue ignore sec...  \n",
       "2222  new directive could put software writer risk l...  \n",
       "2223  man make sure computer network safe secure res...  \n",
       "2224  online role play game time flight reality peop...  \n",
       "\n",
       "[2225 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去除低频词\n",
    "from nltk.probability import *\n",
    "\n",
    "# 过滤频率过低的词\n",
    "def filterfreq(x):\n",
    "    x = x.split()\n",
    "    return ' '.join(word for word in x if fdist[word] >= 10)\n",
    "\n",
    "word_dct = []\n",
    "for news in table['body']:\n",
    "    for word in news.split(' '):\n",
    "        word_dct.append(word)\n",
    "print(word_dct[:10])\n",
    "fdist = FreqDist(word_dct)\n",
    "table['new_body'] = table['new_body'].apply(filterfreq)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3367\n"
     ]
    }
   ],
   "source": [
    "# 保存\n",
    "all_word = set()\n",
    "for body in table['new_body']:\n",
    "    word_list = word_tokenize(body)\n",
    "    for word in word_list:\n",
    "        all_word.add(word)\n",
    "print(len(all_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 写入文件\n",
    "file = open('vocab.txt', mode='w')\n",
    "file.write(' '.join(all_word))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存csv\n",
    "table.to_csv(\"data.csv\", sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base1",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
